# ComparaÃ§Ã£o de Algoritmos de Machine Learning

## ğŸ“‹ DescriÃ§Ã£o

Este projeto implementa uma comparaÃ§Ã£o completa e estatisticamente rigorosa entre quatro algoritmos de Machine Learning para classificaÃ§Ã£o:

- **K-Nearest Neighbors (KNN)**
- **Ãrvores de DecisÃ£o** 
- **Support Vector Machine (SVM)**
- **Multi-Layer Perceptron (MLP)**

O projeto utiliza o dataset "Predict Students' Dropout and Academic Success" e realiza uma anÃ¡lise completa incluindo:
- OtimizaÃ§Ã£o de hiperparÃ¢metros
- AvaliaÃ§Ã£o com mÃºltiplas execuÃ§Ãµes
- Testes estatÃ­sticos (Kruskal-Wallis e Mann-Whitney)
- GeraÃ§Ã£o automÃ¡tica de relatÃ³rios e visualizaÃ§Ãµes

## ğŸš€ Funcionalidades

- âœ… **Pipeline completo de ML**: desde o carregamento dos dados atÃ© a geraÃ§Ã£o de relatÃ³rios
- âœ… **Tuning automÃ¡tico de hiperparÃ¢metros** usando GridSearchCV
- âœ… **AvaliaÃ§Ã£o robusta** com 10 execuÃ§Ãµes independentes
- âœ… **AnÃ¡lise estatÃ­stica** para comparaÃ§Ã£o significativa entre modelos
- âœ… **VisualizaÃ§Ãµes profissionais**: boxplots, heatmaps e grÃ¡ficos radar
- âœ… **RelatÃ³rio HTML automÃ¡tico** com todos os resultados
- âœ… **Logging completo** de todas as etapas

## ğŸ“ Estrutura do Projeto

```
ml-algorithms-comparison/
â”‚
â”œâ”€â”€ main.py                          # Script principal
â”œâ”€â”€ requirements.txt                 # DependÃªncias do projeto
â”œâ”€â”€ README.md                        # Este arquivo
â”‚ 
â”œâ”€â”€ src/                             # CÃ³digo fonte
â”‚   â”œâ”€â”€ config/                      # ConfiguraÃ§Ãµes
â”‚   â”‚   â””â”€â”€ settings.py              # ParÃ¢metros globais
â”‚   â”‚       
â”‚   â”œâ”€â”€ data/                        # Processamento de dados
â”‚   â”‚   â”œâ”€â”€ loader.py                # Carregamento de dados
â”‚   â”‚   â”œâ”€â”€ preprocessor.py          # PrÃ©-processamento
â”‚   â”‚   â””â”€â”€ splitter.py              # DivisÃ£o treino/validaÃ§Ã£o/teste
â”‚   â”‚       
â”‚   â”œâ”€â”€ models/                      # ImplementaÃ§Ã£o dos modelos
â”‚   â”‚   â”œâ”€â”€ base_model.py            # Classe base
â”‚   â”‚   â”œâ”€â”€ knn_model.py             # K-Nearest Neighbors
â”‚   â”‚   â”œâ”€â”€ decision_tree_model.py   # Ãrvore de DecisÃ£o
â”‚   â”‚   â”œâ”€â”€ svm_model.py             # Support Vector Machine
â”‚   â”‚   â””â”€â”€ mlp_model.py             # Multi-Layer Perceptron
â”‚   â”‚       
â”‚   â”œâ”€â”€ tuning/                      # OtimizaÃ§Ã£o de hiperparÃ¢metros
â”‚   â”‚   â””â”€â”€ hyperparameter_tuning.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                  # AvaliaÃ§Ã£o e mÃ©tricas
â”‚   â”‚   â”œâ”€â”€ cross_validation.py      # ValidaÃ§Ã£o cruzada
â”‚   â”‚   â”œâ”€â”€ metrics.py               # CÃ¡lculo de mÃ©tricas
â”‚   â”‚   â””â”€â”€ statistical_tests.py     # Testes estatÃ­sticos
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/               # VisualizaÃ§Ãµes e relatÃ³rios
â”‚   â”‚   â”œâ”€â”€ plots.py                 # GrÃ¡ficos
â”‚   â”‚   â””â”€â”€ report_generator.py      # Gerador de relatÃ³rios
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # UtilitÃ¡rios
â”‚       â”œâ”€â”€ logger.py                # Sistema de logging
â”‚       â””â”€â”€ helpers.py               # FunÃ§Ãµes auxiliares
â”‚       
â””â”€â”€ data/                            # DiretÃ³rio de dados
    â”œâ”€â”€ raw/                         # Dados originais
    â”œâ”€â”€ processed/                   # Dados processados
    â””â”€â”€ results/                     # Resultados gerados
        â”œâ”€â”€ hyperparameters/         # Melhores parÃ¢metros
        â”œâ”€â”€ metrics/                 # MÃ©tricas calculadas
        â”œâ”€â”€ plots/                   # GrÃ¡ficos gerados
        â””â”€â”€ *.html                   # RelatÃ³rios HTML
```

## ğŸ”§ PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)
- Git (opcional, para clonar o repositÃ³rio)

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio (ou baixe o ZIP)

```bash
git clone https://github.com/seu-usuario/ml-algorithms-comparison.git
cd ml-algorithms-comparison
```

### 2. Crie um ambiente virtual (recomendado)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

## ğŸ“Š Dataset

### Estrutura esperada do dataset

O dataset deve conter:
- Features: caracterÃ­sticas dos estudantes (demogrÃ¡ficas, acadÃªmicas, socioeconÃ´micas)
- Target: coluna "Target" indicando a situaÃ§Ã£o do estudante (Dropout, Enrolled, Graduate)

## ğŸƒâ€â™‚ï¸ Como Executar

### 1. Certifique-se de que o ambiente virtual estÃ¡ ativado

```bash
# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### 2. Execute o pipeline completo

```bash
python main.py
```

### 3. Acompanhe o progresso

O script irÃ¡:
1. Carregar e prÃ©-processar os dados
2. Dividir em 50% treino, 25% validaÃ§Ã£o, 25% teste
3. Realizar tuning de hiperparÃ¢metros para cada modelo
4. Avaliar cada modelo 10 vezes
5. Executar testes estatÃ­sticos
6. Gerar visualizaÃ§Ãµes
7. Criar relatÃ³rio HTML completo

### 4. Tempo estimado de execuÃ§Ã£o

- **Total**: 1 minuto (dependendo do hardware)

## ğŸ“ˆ HiperparÃ¢metros Otimizados

### KNN
- **n_neighbors**: [3, 5, 7, 9, 11, 15]
- **weights**: ['uniform', 'distance']

### Ãrvore de DecisÃ£o
- **criterion**: ['gini', 'entropy']
- **max_depth**: [None, 5, 10, 15, 20]
- **min_samples_split**: [2, 5, 10]
- **min_samples_leaf**: [1, 2, 4]

### SVM
- **C**: [0.1, 1, 10, 100]
- **kernel**: ['poly', 'rbf']
- **degree**: [2, 3, 4] (apenas para kernel polinomial)
- **gamma**: ['scale', 'auto']

### MLP
- **hidden_layer_sizes**: [(50,), (100,), (50, 50), (100, 50)]
- **activation**: ['identity', 'logistic', 'tanh', 'relu']
- **learning_rate_init**: [0.001, 0.01, 0.1]
- **max_iter**: [200, 500, 1000]

## ğŸ“Š Resultados

ApÃ³s a execuÃ§Ã£o, vocÃª encontrarÃ¡ em `data/results/`:

### 1. RelatÃ³rio HTML (`relatorio_completo_*.html`)
- Resumo executivo com o melhor modelo
- Tabela com melhores hiperparÃ¢metros
- MÃ©tricas detalhadas (acurÃ¡cia, precisÃ£o, recall, F1-score)
- Resultados dos testes estatÃ­sticos
- ConclusÃµes e recomendaÃ§Ãµes

### 2. VisualizaÃ§Ãµes (`plots/`)
- **accuracy_comparison.png**: Boxplot comparando acurÃ¡cias
- **statistical_tests_heatmap.png**: Heatmap dos p-valores
- **metrics_radar.png**: GrÃ¡fico radar com mÃºltiplas mÃ©tricas

### 3. Arquivo JSON (`summary_*.json`)
- Todos os resultados em formato estruturado
- Ãštil para anÃ¡lises posteriores

### 4. Log detalhado (`ml_comparison_*.log`)
- Registro completo da execuÃ§Ã£o
- Ãštil para debugging

## ğŸ§ª Testes EstatÃ­sticos

### Kruskal-Wallis
- Testa se hÃ¡ diferenÃ§a significativa entre os grupos
- H0: Todos os modelos tÃªm o mesmo desempenho
- Se p-valor < 0.05, rejeita H0

### Mann-Whitney
- ComparaÃ§Ãµes par a par entre modelos
- Identifica quais modelos sÃ£o significativamente diferentes
- CorreÃ§Ã£o de Bonferroni aplicada para mÃºltiplas comparaÃ§Ãµes

## ğŸ› ï¸ PersonalizaÃ§Ã£o

### Modificar parÃ¢metros globais

Edite `src/config/settings.py`:

```python
# DivisÃ£o dos dados
TRAIN_SIZE = 0.5  # 50% para treino
VAL_SIZE = 0.25   # 25% para validaÃ§Ã£o
TEST_SIZE = 0.25  # 25% para teste

# NÃºmero de iteraÃ§Ãµes para avaliaÃ§Ã£o
N_ITERATIONS = 10

# Random state para reprodutibilidade
RANDOM_STATE = 42
```

### Adicionar novos modelos

1. Crie um arquivo em `src/models/novo_modelo.py`
2. Herde da classe `BaseModel`
3. Implemente `get_param_grid()` e `create_model()`
4. Adicione ao dicionÃ¡rio de modelos em `main.py`

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro: "No module named 'src'"
- Execute o `main.py` da raiz do projeto, nÃ£o de dentro de `src/`

### Erro: "File not found: students_dropout.csv"
- Verifique se o arquivo estÃ¡ em `data/raw/students_dropout.csv`
- Confirme se o nome do arquivo estÃ¡ correto

### MemÃ³ria insuficiente
- Reduza o nÃºmero de combinaÃ§Ãµes de hiperparÃ¢metros
- Use um subset dos dados para teste
- Execute um modelo por vez

### Tempo de execuÃ§Ã£o muito longo
- Reduza `N_ITERATIONS` em settings.py
- Simplifique o grid de hiperparÃ¢metros
- Use `n_jobs=1` se tiver problemas com paralelizaÃ§Ã£o

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE.txt) para mais detalhes.

---

**Nota**: Este projeto foi desenvolvido para fins educacionais e de pesquisa em Machine Learning.